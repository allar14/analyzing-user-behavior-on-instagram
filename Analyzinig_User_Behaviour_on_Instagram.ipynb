{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495cb7bf",
   "metadata": {},
   "source": [
    "# Analysing User Behaviour on Instagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac5aeb",
   "metadata": {},
   "source": [
    "The original datasets were provided by HiCounselor(https://www.linkedin.com/company/hicounselor/) as part of online \"Analysing User Behaviour on Instagram\" project.\n",
    "\n",
    "The primary aim of the current part of the project is to preprocess and clean the dataset to prepare it for the analisys using SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1743eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812950a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the file\n",
    "list_of_file_names = [\"comments.csv\", \"follows.csv\", \"likes.csv\", \"photo_tags.csv\", \"photos.csv\", \"tags.csv\", \"users.csv\"]\n",
    "data ={}\n",
    "\n",
    "for name in list_of_file_names:\n",
    "    readed = pd.read_csv('original-source/{}'.format(name))\n",
    "    key_name = name.replace(\".csv\", \"\")\n",
    "    data[key_name] = readed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d2a52",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4903db6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the File: comments\n",
      "   id                 comment  User  id  Photo id created Timestamp   \n",
      "0   1         unde at dolorem         2         1  13-04-2023 08:04  \\\n",
      "1   2         quae ea ducimus         3         1  13-04-2023 08:04   \n",
      "2   3      alias a voluptatum         5         1  13-04-2023 08:04   \n",
      "3   4    facere suscipit sunt        14         1  13-04-2023 08:04   \n",
      "4   5  totam eligendi quaerat        17         1  13-04-2023 08:04   \n",
      "\n",
      "  posted date emoji used  Hashtags used count  \n",
      "0    April 14        yes                    1  \n",
      "1    April 14         no                    2  \n",
      "2    April 14         no                    4  \n",
      "3    April 14        yes                    2  \n",
      "4    April 14        yes                    1  \n",
      "\n",
      "\n",
      "Name of the File: follows\n",
      "   follower  followee       created time  is follower active   \n",
      "0         2          1  13-04-2023 08:04                   1  \\\n",
      "1         2          3  13-04-2023 08:04                   0   \n",
      "2         2          4  13-04-2023 08:04                   0   \n",
      "3         2          5  13-04-2023 08:04                   0   \n",
      "4         2          6  13-04-2023 08:04                   1   \n",
      "\n",
      "  followee Acc status  \n",
      "0             Private  \n",
      "1             private  \n",
      "2              public  \n",
      "3             private  \n",
      "4             private  \n",
      "\n",
      "\n",
      "Name of the File: likes\n",
      "   user   photo      created time following or not    like type\n",
      "0      2      1  13-04-2023 08:04              yes  heart emoji\n",
      "1      2      4  13-04-2023 08:04               no    thumbs up\n",
      "2      2      8  13-04-2023 08:04              yes     laughing\n",
      "3      2      9  13-04-2023 08:04               no         fire\n",
      "4      2     10  13-04-2023 08:04              yes         clap\n",
      "\n",
      "\n",
      "Name of the File: photo_tags\n",
      "   photo  tag ID  user id\n",
      "0      1      13        1\n",
      "1      1      17        1\n",
      "2      1      18        2\n",
      "3      1      19        2\n",
      "4      1      21        3\n",
      "\n",
      "\n",
      "Name of the File: photos\n",
      "   id            image link  user ID       created dat Insta filter used   \n",
      "0   1     http://elijah.biz        1  13-04-2023 08:04               yes  \\\n",
      "1   2    https://shanon.org        1  13-04-2023 08:04                no   \n",
      "2   3      http://vicky.biz        1  13-04-2023 08:04                no   \n",
      "3   4      http://oleta.net        1  13-04-2023 08:04                no   \n",
      "4   5  https://jennings.biz        1  13-04-2023 08:04               yes   \n",
      "\n",
      "  photo type  \n",
      "0      photo  \n",
      "1      photo  \n",
      "2      photo  \n",
      "3      photo  \n",
      "4      photo  \n",
      "\n",
      "\n",
      "Name of the File: tags\n",
      "   id     tag text      created time       location\n",
      "0   1       sunset  13-04-2023 08:04        florida\n",
      "1   2  photography  13-04-2023 08:04  washington DC\n",
      "2   3      sunrise  13-04-2023 08:04       new york\n",
      "3   4    landscape  13-04-2023 08:04         london\n",
      "4   5         food  13-04-2023 08:04         brazil\n",
      "\n",
      "\n",
      "Name of the File: users\n",
      "   id           name      created time private/public  post count   \n",
      "0   1  Kenton_Kirlin  16-02-2017 18:22            yes          11  \\\n",
      "1   2  Andre_Purdy85  02-04-2017 17:11             no           7   \n",
      "2   3  Harley_Lind18  21-02-2017 11:12             no           2   \n",
      "3   4  Arely_Bogan63  13-08-2016 01:28            yes           1   \n",
      "4   5  Aniya_Hackett  07-12-2016 01:04            yes           3   \n",
      "\n",
      "  Verified status  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in data:\n",
    "    print(\"Name of the File: \"'{}'.format(file))\n",
    "    print(data['{}'.format(file)].head(5))\n",
    "    print(\"\\n\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65188c53",
   "metadata": {},
   "source": [
    "## Cleaning the dataset\n",
    "Data Cleaning is a process of identifying and removing irrelevant or redundant columns and renaming the columns to make them more descriptive and consistent with the content of the dataset. This improves the quality and usability of the data for analysis and modeling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a849ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of column names that need to be removed or renamed was provided by project organazer as part of task\n",
    "\n",
    "names_to_drop = {'comments':{'drop':[\"posted date\",\"emoji used\",\"Hashtags used count\"],\n",
    "                            'rename':{'comment':'comment_text', 'User  id':'user_id',\n",
    "                                      'Photo id': 'photo_id', 'created Timestamp':'created_at'}},\n",
    "                'follows':{'drop':[\"is follower active\",\"followee Acc status\"],\n",
    "                            'rename':{'follower':'follower_id','followee ':'followee_id','created time':'created_at'}},\n",
    "                 'likes':{'drop':[\"following or not\",\"like type\"],\n",
    "                            'rename':{'user ':'user_id','photo':'photo_id','created time':'created_at'}},\n",
    "                 'photo_tags':{'drop':[\"user id\"],\n",
    "                            'rename':{'photo':'photo_id','tag ID':'tag_id'}},\n",
    "                 'photos':{'drop':[\"Insta filter used\",\"photo type\"],\n",
    "                            'rename':{'image link':'image_url','user ID':'user_id','created dat':'created_date'}},\n",
    "                 'tags':{'drop':[\"location\"],\n",
    "                            'rename':{'tag text':'tag_name','created time':'created_at'}},\n",
    "                 'users':{'drop':[\"private/public\",\"post count\",\"Verified status\"],\n",
    "                            'rename':{'name':'username','created time':'created_at'}}}\n",
    "\n",
    "for key in names_to_drop.keys():\n",
    "    a = names_to_drop[key]\n",
    "    for akey in a.keys():\n",
    "        if akey == 'drop':\n",
    "            data[key].drop(columns = a[akey], inplace=True)\n",
    "        if akey == 'rename':\n",
    "            data[key].rename(columns = a[akey], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a7c3280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>photo_id</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unde at dolorem</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13-04-2023 08:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>quae ea ducimus</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13-04-2023 08:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>alias a voluptatum</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13-04-2023 08:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>facere suscipit sunt</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13-04-2023 08:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>totam eligendi quaerat</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13-04-2023 08:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7483</th>\n",
       "      <td>7484</td>\n",
       "      <td>accusamus vel est</td>\n",
       "      <td>82</td>\n",
       "      <td>257</td>\n",
       "      <td>13-04-2023 08:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7484</th>\n",
       "      <td>7485</td>\n",
       "      <td>sit nulla qui</td>\n",
       "      <td>91</td>\n",
       "      <td>257</td>\n",
       "      <td>13-04-2023 08:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>7486</td>\n",
       "      <td>sed quidem vitae</td>\n",
       "      <td>93</td>\n",
       "      <td>257</td>\n",
       "      <td>13-04-2023 08:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>7487</td>\n",
       "      <td>dolorem eveniet rerum</td>\n",
       "      <td>95</td>\n",
       "      <td>257</td>\n",
       "      <td>13-04-2023 08:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>7488</td>\n",
       "      <td>dolores nihil voluptas</td>\n",
       "      <td>96</td>\n",
       "      <td>257</td>\n",
       "      <td>13-04-2023 08:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7488 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            comment_text  user_id  photo_id        created_at\n",
       "0        1         unde at dolorem        2         1  13-04-2023 08:04\n",
       "1        2         quae ea ducimus        3         1  13-04-2023 08:04\n",
       "2        3      alias a voluptatum        5         1  13-04-2023 08:04\n",
       "3        4    facere suscipit sunt       14         1  13-04-2023 08:04\n",
       "4        5  totam eligendi quaerat       17         1  13-04-2023 08:04\n",
       "...    ...                     ...      ...       ...               ...\n",
       "7483  7484       accusamus vel est       82       257  13-04-2023 08:04\n",
       "7484  7485           sit nulla qui       91       257  13-04-2023 08:04\n",
       "7485  7486        sed quidem vitae       93       257  13-04-2023 08:04\n",
       "7486  7487   dolorem eveniet rerum       95       257  13-04-2023 08:04\n",
       "7487  7488  dolores nihil voluptas       96       257  13-04-2023 08:04\n",
       "\n",
       "[7488 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking one dataset for correctness\n",
    "data['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d245421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export cleaned datasets to newcsv files\n",
    "\n",
    "for key in data.keys():\n",
    "    data[key].to_csv(path_or_buf = \n",
    "                   'original-cleaned/{}_cleaned.csv'.format(key), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02642581",
   "metadata": {},
   "source": [
    "The cleaned datasets were uploaded into SQL database. For further analysis please refer to 'Analysing_User_Behaviour_on_Instagram.sql' file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
